{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sw_industry_list(industry_code): # 不用 list ，用 text 输入\n",
    "    \n",
    "    # 引入所需包\n",
    "    from bs4 import BeautifulSoup\n",
    "    import requests\n",
    "    import urllib\n",
    "    import pandas as pd\n",
    "    \n",
    "    # 读取数据文件\n",
    "    html_doc = urllib.request.urlopen('http://www.swsindex.com/downfile.aspx?code=' + industry_code).read()\n",
    "    \n",
    "    # 用 lmxl 解析数据文件\n",
    "    soup0 = BeautifulSoup(html_doc, \"lxml\")\n",
    "    \n",
    "    # 分离出 table\n",
    "    table1 = soup0.find_all('table')[0]\n",
    "    \n",
    "    # 准备 list1、list2 两个空 list 备用\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    \n",
    "    # 处理 th 即标题\n",
    "    \n",
    "    for i in range(0, len(table1.find_all('th'))):\n",
    "        list2.append(table1.find_all('th')[i].text)\n",
    "        \n",
    "    # 将标题存入 list1\n",
    "    list1.append(list2)\n",
    "    \n",
    "    # 再次将 list2 清空\n",
    "    list2 = []\n",
    "    \n",
    "    # 第一层循环，依次读取每一行 tr\n",
    "    for i in range(1, len(table1.find_all('tr'))):\n",
    "        \n",
    "        # 每次将 list2 清空备用\n",
    "        list2 = []\n",
    "        \n",
    "        # 第二层循环，读取每个 td 元素，其 text 依次存入 list2\n",
    "        for j in table1.find_all('tr')[i].find_all('td'):\n",
    "            list2.append(j.text)\n",
    "            \n",
    "        # 将写入的 list2 文件附加到 list1,循环完成即生成包函完整数据的 list1\n",
    "        list1.append(list2)\n",
    "        \n",
    "    # 整理生成的 DataFrame\n",
    "    datatemp = pd.DataFrame(list1[1:], columns = list1[0])\n",
    "    datatemp.index = datatemp['证券代码']\n",
    "    datatemp.index.name = 'code'\n",
    "    datatemp['文件夹'] = '/home/wangshi/reports/stock_reports/' + industry_code + '/' + datatemp['证券代码'] + '_' + datatemp['证券名称'] + '/'\n",
    "    \n",
    "    \n",
    "    # 返回股票清单 DataFrame, 后用 list 函数返回\n",
    "    return datatemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = get_sw_industry_list('801120')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>证券代码</th>\n",
       "      <th>证券名称</th>\n",
       "      <th>最新权重(%)</th>\n",
       "      <th>计入日期</th>\n",
       "      <th>文件夹</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000019</th>\n",
       "      <td>000019</td>\n",
       "      <td>深深宝A</td>\n",
       "      <td>0.6165</td>\n",
       "      <td>2008-6-2 0:00:00</td>\n",
       "      <td>/home/wangshi/reports/stock_reports/801120/000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          证券代码  证券名称 最新权重(%)              计入日期  \\\n",
       "code                                             \n",
       "000019  000019  深深宝A  0.6165  2008-6-2 0:00:00   \n",
       "\n",
       "                                                      文件夹  \n",
       "code                                                       \n",
       "000019  /home/wangshi/reports/stock_reports/801120/000...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/wangshi/reports/stock_reports/801120/000019_深深宝A/'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['文件夹'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/wangshi/reports/stock_reports/801120/000019_深深宝A/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['文件夹'].loc['000019']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 此处用 list 输入 codes，可试用 list + DataFrame 输入\n",
    "def get_eastmoney_stock_report(urls, paths):\n",
    "    \n",
    "    # 下载个股\n",
    "    from dateutil.parser import parse\n",
    "    from bs4 import BeautifulSoup\n",
    "    import requests, urllib, os, shutil, json\n",
    "    import pandas as pd\n",
    "    \n",
    "    # 此处待添加验证 urls 是否为 DataFrame\n",
    "    count_download = 0\n",
    "    count_pass = 0\n",
    "    count_fail = 0\n",
    "    for i in range(0, len(urls)):\n",
    "        temp_url = 'http://data.eastmoney.com/report/' + parse(urls.loc[urls.index[i]]['datetime']).strftime('%Y'+'%m'+'%d') + '/' + urls.loc[urls.index[i]]['infoCode'] + '.html'\n",
    "        # print(temp_url)\n",
    "        html_doc = urllib.request.urlopen(temp_url).read()\n",
    "        soup = BeautifulSoup(html_doc, \"lxml\")\n",
    "        try:\n",
    "            file_url = soup.find_all(text = '查看PDF原文')[0].parent.get('href')\n",
    "            temp_name = paths + parse(urls.loc[urls.index[i]]['datetime']).strftime('%C'+'%m'+'%d') + '_' + urls.loc[urls.index[i]]['insName'] + '_' + urls.loc[urls.index[i]]['title'] + '.pdf'\n",
    "        \n",
    "            if os.path.isfile(temp_name) == True:\n",
    "                # print('File already exist! PASS!')\n",
    "                count_pass += 1\n",
    "                pass\n",
    "            else:\n",
    "                urllib.request.urlretrieve(file_url, temp_name)\n",
    "                count_download += 1\n",
    "                # print('Download ' + str(count_download) + '/' + str(len(urls)) + ' new files '+ 'Successfully !')\n",
    "        except:\n",
    "            print('Fail to get the file. ' + 'Please download the file manually !' + '\\n'  + temp_url)\n",
    "            count_fail += 1\n",
    "            pass\n",
    "        \n",
    "    print('    DOWN: ' + str(count_download) + '/' + str(len(urls)) + '\\n'  + '    PASS: ' + str(count_pass) + '/' + str(len(urls)) + '\\n'   + '    FAIL: ' + str(count_fail) + '/' + str(len(urls)))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 通过输入股票代码列表下载股票报告清单到硬盘\n",
    "def get_stock_report_list(DataFrame, path):\n",
    "    \n",
    "    \n",
    "    from bs4 import BeautifulSoup\n",
    "    from math import ceil\n",
    "    import requests, urllib, os, shutil, json\n",
    "    import pandas as pd\n",
    "    \n",
    "    \n",
    "    # 第一层循环，遍历列表中每个股票代码，取得其报告页数\n",
    "    for stock_code in list(DataFrame['证券代码']):\n",
    "        \n",
    "        try:\n",
    "            url_data_0 = 'http://datainterface.eastmoney.com//EM_DataCenter/js.aspx?type=SR&sty=GGSR&js=var%20PrnJnSby={%22data%22:[(x)],%22pages%22:%22(pc)%22,%22update%22:%22(ud)%22,%22count%22:%22(count)%22}&ps=25&p=1&code=' + stock_code\n",
    "            html_doc_0 = urllib.request.urlopen(url_data_0).read()\n",
    "            soup_0 = BeautifulSoup(html_doc_0, \"lxml\")\n",
    "        \n",
    "            # 用 json 处理得到的 json 文本\n",
    "            jsontext_0 = json.loads(soup_0.text.split('=')[1])\n",
    "        \n",
    "            # 向上取整取得报告页数\n",
    "            page_numbers = ceil(int(jsontext_0['count'])/25)\n",
    "        \n",
    "            data_0 = []\n",
    "        \n",
    "            # 第二层循环，遍历股票报告页面，取得其报告编码\n",
    "            for page_number in range(1, page_numbers + 1):\n",
    "            \n",
    "                url_data_1 = 'http://datainterface.eastmoney.com//EM_DataCenter/js.aspx?type=SR&sty=GGSR&js=var%20PrnJnSby={%22data%22:[(x)],%22pages%22:%22(pc)%22,%22update%22:%22(ud)%22,%22count%22:%22(count)%22}&ps=25&p=' + str(page_number) + '&code=' + stock_code\n",
    "                html_doc_1 = urllib.request.urlopen(url_data_1).read()\n",
    "                soup_1 = BeautifulSoup(html_doc_1, \"lxml\")\n",
    "            \n",
    "                # 用 json 处理得到的 json 文本\n",
    "                jsontext_1 = json.loads(soup_1.text.split('=')[1])\n",
    "            \n",
    "                #合并新的列表\n",
    "                data_0 += jsontext_1['data']\n",
    "        \n",
    "            #处理取得的编码为DataFrame，并将结果存盘\n",
    "            data_1 = pd.DataFrame(data_0)\n",
    "            data_1.index = data_1['infoCode']\n",
    "            data_1.index.name = 'infoCodes' # 为避免名称重复这里设置为 infoCodes\n",
    "            \n",
    "            get_eastmoney_stock_report(data_1, DataFrame['文件夹'].loc[stock_code])\n",
    "            \n",
    "            data_1.to_csv(path + stock_code)\n",
    "        \n",
    "        except:\n",
    "            print('Fail to get reports of ' + stock_code)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "industry_codes = ['801120', '801150'] # 食品饮料、医药生物\n",
    "industry_paths = []\n",
    "for i in industry_codes:\n",
    "    t = '/home/wangshi/script/stocks_reports_list/industry_lists/' + i + '/'\n",
    "    industry_paths.append(t)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/wangshi/script/stocks_reports_list/industry_lists/801120/',\n",
       " '/home/wangshi/script/stocks_reports_list/industry_lists/801150/']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "industry_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "industry_lists = []\n",
    "for i in industry_codes:\n",
    "    temp_df = get_sw_industry_list(i)\n",
    "    industry_lists.append(list(temp_df['证券代码']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['000019',\n",
       "  '000557',\n",
       "  '000568',\n",
       "  '000596',\n",
       "  '000716',\n",
       "  '000729',\n",
       "  '000752',\n",
       "  '000799',\n",
       "  '000848',\n",
       "  '000858',\n",
       "  '000860',\n",
       "  '000869',\n",
       "  '000895',\n",
       "  '000929',\n",
       "  '000995',\n",
       "  '002216',\n",
       "  '002304',\n",
       "  '002329',\n",
       "  '002330',\n",
       "  '002387',\n",
       "  '002461',\n",
       "  '002481',\n",
       "  '002495',\n",
       "  '002507',\n",
       "  '002515',\n",
       "  '002557',\n",
       "  '002568',\n",
       "  '002570',\n",
       "  '002582',\n",
       "  '002646',\n",
       "  '002650',\n",
       "  '002661',\n",
       "  '002695',\n",
       "  '002702',\n",
       "  '002719',\n",
       "  '002726',\n",
       "  '002732',\n",
       "  '002770',\n",
       "  '300146',\n",
       "  '600059',\n",
       "  '600073',\n",
       "  '600084',\n",
       "  '600090',\n",
       "  '600132',\n",
       "  '600186',\n",
       "  '600197',\n",
       "  '600199',\n",
       "  '600238',\n",
       "  '600300',\n",
       "  '600305',\n",
       "  '600365',\n",
       "  '600381',\n",
       "  '600429',\n",
       "  '600519',\n",
       "  '600543',\n",
       "  '600559',\n",
       "  '600573',\n",
       "  '600597',\n",
       "  '600600',\n",
       "  '600616',\n",
       "  '600702',\n",
       "  '600779',\n",
       "  '600809',\n",
       "  '600866',\n",
       "  '600872',\n",
       "  '600873',\n",
       "  '600887',\n",
       "  '601579',\n",
       "  '603020',\n",
       "  '603027',\n",
       "  '603031',\n",
       "  '603198',\n",
       "  '603288',\n",
       "  '603369',\n",
       "  '603589',\n",
       "  '603696',\n",
       "  '603779',\n",
       "  '603866',\n",
       "  '603919'],\n",
       " ['000004',\n",
       "  '000028',\n",
       "  '000078',\n",
       "  '000150',\n",
       "  '000153',\n",
       "  '000403',\n",
       "  '000411',\n",
       "  '000423',\n",
       "  '000503',\n",
       "  '000513',\n",
       "  '000518',\n",
       "  '000538',\n",
       "  '000566',\n",
       "  '000590',\n",
       "  '000597',\n",
       "  '000606',\n",
       "  '000623',\n",
       "  '000650',\n",
       "  '000661',\n",
       "  '000705',\n",
       "  '000739',\n",
       "  '000756',\n",
       "  '000766',\n",
       "  '000788',\n",
       "  '000790',\n",
       "  '000908',\n",
       "  '000915',\n",
       "  '000919',\n",
       "  '000952',\n",
       "  '000963',\n",
       "  '000989',\n",
       "  '000990',\n",
       "  '000999',\n",
       "  '002001',\n",
       "  '002007',\n",
       "  '002019',\n",
       "  '002020',\n",
       "  '002022',\n",
       "  '002030',\n",
       "  '002038',\n",
       "  '002044',\n",
       "  '002099',\n",
       "  '002107',\n",
       "  '002118',\n",
       "  '002166',\n",
       "  '002198',\n",
       "  '002219',\n",
       "  '002223',\n",
       "  '002252',\n",
       "  '002262',\n",
       "  '002275',\n",
       "  '002287',\n",
       "  '002294',\n",
       "  '002317',\n",
       "  '002332',\n",
       "  '002349',\n",
       "  '002365',\n",
       "  '002370',\n",
       "  '002390',\n",
       "  '002393',\n",
       "  '002399',\n",
       "  '002411',\n",
       "  '002412',\n",
       "  '002422',\n",
       "  '002424',\n",
       "  '002432',\n",
       "  '002433',\n",
       "  '002437',\n",
       "  '002462',\n",
       "  '002550',\n",
       "  '002551',\n",
       "  '002566',\n",
       "  '002581',\n",
       "  '002589',\n",
       "  '002603',\n",
       "  '002626',\n",
       "  '002644',\n",
       "  '002653',\n",
       "  '002675',\n",
       "  '002680',\n",
       "  '002693',\n",
       "  '002727',\n",
       "  '002728',\n",
       "  '002737',\n",
       "  '002750',\n",
       "  '002758',\n",
       "  '002773',\n",
       "  '002788',\n",
       "  '300003',\n",
       "  '300006',\n",
       "  '300009',\n",
       "  '300015',\n",
       "  '300016',\n",
       "  '300026',\n",
       "  '300030',\n",
       "  '300039',\n",
       "  '300049',\n",
       "  '300086',\n",
       "  '300110',\n",
       "  '300122',\n",
       "  '300142',\n",
       "  '300147',\n",
       "  '300158',\n",
       "  '300171',\n",
       "  '300181',\n",
       "  '300194',\n",
       "  '300199',\n",
       "  '300204',\n",
       "  '300206',\n",
       "  '300216',\n",
       "  '300233',\n",
       "  '300238',\n",
       "  '300239',\n",
       "  '300244',\n",
       "  '300246',\n",
       "  '300254',\n",
       "  '300255',\n",
       "  '300261',\n",
       "  '300267',\n",
       "  '300273',\n",
       "  '300289',\n",
       "  '300294',\n",
       "  '300298',\n",
       "  '300314',\n",
       "  '300318',\n",
       "  '300326',\n",
       "  '300347',\n",
       "  '300357',\n",
       "  '300358',\n",
       "  '300363',\n",
       "  '300381',\n",
       "  '300396',\n",
       "  '300401',\n",
       "  '300404',\n",
       "  '300406',\n",
       "  '300412',\n",
       "  '300436',\n",
       "  '300439',\n",
       "  '300452',\n",
       "  '300453',\n",
       "  '300463',\n",
       "  '300482',\n",
       "  '300485',\n",
       "  '300497',\n",
       "  '300519',\n",
       "  '300529',\n",
       "  '600055',\n",
       "  '600056',\n",
       "  '600062',\n",
       "  '600079',\n",
       "  '600080',\n",
       "  '600085',\n",
       "  '600129',\n",
       "  '600161',\n",
       "  '600196',\n",
       "  '600211',\n",
       "  '600216',\n",
       "  '600222',\n",
       "  '600252',\n",
       "  '600267',\n",
       "  '600272',\n",
       "  '600276',\n",
       "  '600285',\n",
       "  '600329',\n",
       "  '600332',\n",
       "  '600351',\n",
       "  '600380',\n",
       "  '600420',\n",
       "  '600422',\n",
       "  '600436',\n",
       "  '600479',\n",
       "  '600488',\n",
       "  '600511',\n",
       "  '600513',\n",
       "  '600518',\n",
       "  '600521',\n",
       "  '600529',\n",
       "  '600530',\n",
       "  '600535',\n",
       "  '600557',\n",
       "  '600566',\n",
       "  '600572',\n",
       "  '600587',\n",
       "  '600594',\n",
       "  '600613',\n",
       "  '600645',\n",
       "  '600664',\n",
       "  '600671',\n",
       "  '600713',\n",
       "  '600721',\n",
       "  '600750',\n",
       "  '600763',\n",
       "  '600767',\n",
       "  '600771',\n",
       "  '600781',\n",
       "  '600789',\n",
       "  '600796',\n",
       "  '600812',\n",
       "  '600829',\n",
       "  '600833',\n",
       "  '600851',\n",
       "  '600867',\n",
       "  '600976',\n",
       "  '600993',\n",
       "  '600998',\n",
       "  '601607',\n",
       "  '603108',\n",
       "  '603168',\n",
       "  '603222',\n",
       "  '603309',\n",
       "  '603368',\n",
       "  '603456',\n",
       "  '603520',\n",
       "  '603567',\n",
       "  '603669',\n",
       "  '603883',\n",
       "  '603939',\n",
       "  '603998']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "industry_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-4840f1d083bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindustry_lists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mget_stock_report_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/home/wangshi/script/stocks_reports_list/industry_lists/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m# 此处实际已经导出 DataFrame ，可直接接 get_eastmoney_stock_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-7842afa35522>\u001b[0m in \u001b[0;36mget_stock_report_list\u001b[0;34m(DataFrame, path)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# 第一层循环，遍历列表中每个股票代码，取得其报告页数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mstock_code\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'证券代码'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "for i in industry_lists:\n",
    "    get_stock_report_list(i, '/home/wangshi/script/stocks_reports_list/industry_lists/')\n",
    "    # 此处实际已经导出 DataFrame ，可直接接 get_eastmoney_stock_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_stock_report_list(df, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
